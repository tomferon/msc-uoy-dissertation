\documentclass[a4paper]{article}

\usepackage{lastpage}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
\renewcommand{\headrulewidth}{0pt}
\fancyfoot{}
\fancyfoot[LE,RO]{\thepage \thinspace\thinspace of \pageref{LastPage}}
% \fancyfoot[RE,LO]{Dissertation}

\usepackage[utf8]{inputenc}
\usepackage{amsthm}
\newtheorem{definition}{Definition}[section]
\newtheorem{lemma}[definition]{Lemma}
\newtheorem{proposition}[definition]{Proposition}
\newtheorem{theorem}[definition]{Theorem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}

\usepackage[backend=biber]{biblatex}
\addbibresource{bibliography.bib}

\begin{document}

\section*{Scratch}

\begin{align*}
  \mathrm{d}\theta = a(t) \mathrm{d}t + b(t) \mathrm{d}W(t)\\
  G(t,x) = ??\\
  \mathrm{d}G(t,\theta(t)) = \theta(t) \mathrm{d}t + \theta^2(t) \mathrm{d}W(t)\\
  \mathrm{d}G(t,\theta(t)) = (G_t + G_x a + \frac{1}{2} G_{xx} b^2) \mathrm{d}t + G_x b \mathrm{d}W(t)\\
  \\
  G_t + G_x a + \frac{1}{2} G_{xx} b^2 = \theta\\
  G_x b = \theta^2\\
  \\
  \int_0^t \theta(s) \mathrm{d}s + \int_0^t \theta^2(s) \mathrm{d}W(s)
\end{align*}

\begin{align*}
  \mathrm{d}X(t) &= a_X(t) \mathrm{d}t + b_X(t) \mathrm{d}W(t)\\
  \mathrm{d}Y(t) &= a_Y(t) \mathrm{d}t + b_Y(t) \mathrm{d}W(t)\\
  F(t,x,y) &= \exp ( -G(t,x) - G(t,y) )\\
\end{align*}

\begin{align*}
  \mathrm{d}X(t) &= a(t) \mathrm{d}t + b(t) \mathrm{d}W(t)\\
  \mathrm{d}Y(t) &= \theta(t) \mathrm{d}t + \mathrm{d}W(t)\\
  \mathrm{d}XY &= X(t) \theta(t) \mathrm{d}t + X(t) \mathrm{d}W(t) + a(t) Y(t) \mathrm{d}t + b(t) Y(t) \mathrm{d}W(t) + b(t) \mathrm{d}t\\
  &= \left(X(t) \theta(t) + a(t) Y(t) + b(t) \right) \mathrm{d}t + \left(X(t) + b(t) Y(t) \right) \mathrm{d}W(t)\\
\end{align*}

\pagebreak

FIXME: Quick intro to the topic and explanation of what is coming.

\section{Preliminaries}

% Develop a preliminaries section, in which the tools of stochastic Ito calculus are introduced. Assume that your reader has background in the standard undergraduate modules in mathematics (including analysis, measure theory, probability theory and statistics), but introduce all the notions concerning stochastic processes from scratch. This section should not contain any proofs. Simply set up and state the needed results, providing citations to sources. While developing this section, restrict to the setup needed for the model from [2].

This section establishes the preliminaries of stochastic calculus required by further sections without proofs. See \textcite{capinski_stochastic_2012} and \textcite{capinski_blackscholes_2012} for further details.

In the following, we implicitly assume that we work in a probability space $(\Omega, \mathcal{F}, P)$ unless stated otherwise. We also restrict ourselves to processes defined on a time interval $[0,T]$ for some $T$ as it is sufficient in this context. When relevant, we further assume that we work with a filtration $(\mathcal{F}_t)_{t \in [0,T]}$.

\begin{definition}
  A \textbf{stochastic process} is a measurable function $X : [0,T] \times \Omega \to \mathbb{R}^d$ with respect to the $\sigma$-field $\mathcal{B}([0,T]) \times \mathcal{F}$.
\end{definition}

Note that $X(t)$ for $t \in [0,T]$ denotes the random variable $\omega \mapsto X(t,\omega)$.

\begin{definition}
  A \textbf{filtration} is a family $(\mathcal{F}_t)_{t \in [0,T]}$ of sub-$\sigma$-fields of $\mathcal{F}$ such that $\mathcal{F}_s \subseteq \mathcal{F}_t$ for all $0 \le s < t \le T$.
\end{definition}

Consider a stochastic process $X$ in the probability space $(\Omega, \mathcal{F}, P)$. We denote the \textbf{filtration generated by $X$} by $(\mathcal{F}^X_t)_{t \in [0,T]}$ with

\begin{align*}
  \mathcal{F}^X_t = \sigma \left\{ A : A \in \mathcal{F}_{X(s)}, s \in [0,t] \right\}
\end{align*}

where $\mathcal{F}_{Y}$ denotes the sub-$\sigma$-field of $\mathcal{F}$ generated by $Y$ for any $\mathcal{F}$-measurable random variable $Y$.

\begin{definition}
  A stochastic process $X$ is said to be \textbf{adapted} to a filtration $(\mathcal{F}_t)_{t \in [0,T]}$ if for all $t \in [0,T]$, $X(t)$ is $\mathcal{F}_t$-measurable.
\end{definition}

\begin{definition}
  A stochastic process $X$ is said to be a \textbf{martingale} for a filtration $\mathcal{F}_t$ if $X(t)$ is integrable for each $t \in [0,T]$ and

  \begin{align*}
    \mathbb{E}(X(t) \mid \mathcal{F}_s) = X(s)
  \end{align*}

  for all $0 \le s < t \le T$.
\end{definition}

A very important stochastic process is the Wiener process. Here, we give an axiomatic definition. For a construction of such a process and thus a proof of existence, see \textcite{capinski_stochastic_2012}.

\begin{definition}
  A \textbf{Wiener process}, also called Brownian motion, is a stochastic process $(W(t))_{t \in [0,T]}$ that satisfies

  \begin{itemize}
    \item $W(0) = 0$ almost surely,
    \item for all $0 \le s < t \le T$, the increment $W(t) - W(s)$ follows a normal distribution with mean 0 and variance $t - s$,
    \item for all $0 \le t_1 < t_2 < \cdots < t_m$, the increments $W(t_k) - W(t_{k-1}), k=2,\ldots,m$ are independent,
    \item almost all paths are continuous, i.e. $t \mapsto W(t,\omega)$ are continuous functions for almost all $\omega \in \Omega$.
  \end{itemize}
\end{definition}

\begin{definition}
  A \textbf{$d$-dimensional Wiener process} is a stochastic process $\mathbf{W}(t) = (W_1(t), W_2(t), \ldots, W_d(t))$ where $W_j(t), j=1,\ldots,n$ are independent Wiener processes.
\end{definition}

We define the \textit{stochastic integral} on so-called simple processes in $\mathcal{S}^2$ and then extend it to a larger class of processes $\mathcal{M}^2$ as defined below. Note that $\mathcal{S}^2 \subset \mathcal{M}^2$. A complete development of stochastic integrals on $\mathcal{S}^2 \subset \mathcal{M}^2 \subset \mathcal{P}^2$ with their properties can be found in \textcite{capinski_stochastic_2012}.

\begin{align*}
  \mathcal{S}^2 &= \{ (t,\omega) \mapsto \xi_0 \mathbf{1}_0 + \sum_{k=0}^{n-1} \xi_k(\omega) \mathbf{1}_{(t_k,t_{k+1}]}(t)\\
    &\ \ \ \ \ : n > 0, 0 = t_0 < t_1 < \cdots < t_n = T,\\
    &\ \ \ \ \ \ \ \xi_k \text{ is } \mathcal{F}_{t_k}\text{-measurable and } \mathbb{E}(\xi_k^2) < \infty \text{ for } k = 0,1,\ldots,n-1 \},\\
  \mathcal{M}^2 &= \left\{ f : [0,T] \times \Omega \to \mathbb{R} : f \text{ is adpated }, \mathbb{E}\left(\int_0^T f(t)^2 \mathrm{d}t \right) < \infty \right\}.
\end{align*}

\begin{definition}
  The \textbf{stochastic integral}, also called It\^o integral, of a process $f \in \mathcal{S}^2$ is

  \begin{align*}
    \int_0^T f(t) \mathrm{d}W(t) = \sum_{k=0}^{n-1} \xi_k (W(t_{k+1}) - W(t_k)).
  \end{align*}
\end{definition}

\begin{proposition}\label{prop:s2-m2-conv}
  For all $f \in \mathcal{M}^2$, there exists a sequence $(f_n)_{n \ge 1}$ in $\mathcal{S}^2$ that converges to $f$ in $L^2([0,T] \times \Omega)$.
\end{proposition}

This proposition allows us to extend the stochastic integral to $\mathcal{M}^2$ as follows.

\begin{definition}
  The \textbf{stochastic integral} of $f \in \mathcal{M}^2$ is

  \begin{align*}
    \int_0^T f(t) \mathrm{d}W(t) = \lim_{n \to \infty} \int_0^T f_n(t) \mathrm{d}W(t).
  \end{align*}
\end{definition}

It can be shown that the limit in this definition exists and does not in fact depend on which specific sequence $(f_n)$ convergent to $f$ we choose. This together with \eqref{prop:s2-m2-conv} ensures that the stochastic integral is well-defined on $\mathcal{M}^2$. See \textcite{capinski_stochastic_2012}.

Furthermore, for all $f \in \mathcal{M}^2$, there exists a continuous martingale $M$ such that for all $t$,

\begin{align*}
  P\left(M(t) = \int_0^T \mathbf{1}_{[0,t]}(s) f(s) \mathrm{d}W(s)\right) = 1.
\end{align*}

This allows to see stochastic integrals as processes defining

\begin{align*}
  \int_0^t f(s) \mathrm{d}W(s) = M(t).
\end{align*}

FIXME: The above is not unique but all such martingales are versions of one another.

\begin{definition}
  An \textbf{It\^o process} is a stochastic process $X$ of the form

  \begin{align}\label{def:ito-process}
    X(t) = X(0) + \int_0^t a(s) \mathrm{d}s + \int_0^t b(s) \mathrm{d}W(s),
  \end{align}

  for $t \in [0,T]$ where $a,b$ are called the \textbf{characteristics} of $X$.
\end{definition}

For convenience, we will also write \eqref{eq:def-ito-process} using the following notation, its \textbf{stochastic differential}:

\begin{align}\label{eq:stoch-diff-notation}
  \mathrm{d}X(t) = a(t) \mathrm{d}t + b(t) \mathrm{d}W(t).
\end{align}

FIXME: Uniqueness of characteristics

Consider a so-called \textbf{stochastic differential equation}, or \textbf{SDE} for short, as follows.

\begin{align}\label{eq:sde-init-value}
  \mathrm{d}X(t) &= a(t,X(t)) \mathrm{d}t + b(t,X(t)) \mathrm{d}W(t), \text{ for } t \in (0,T],\\
  X(0) &= X_0\notag
\end{align}

where $X_0$ is a given square-integrable random variable.

Under certain conditions, we know that it has a unique solution, i.e. we have both existence and uniqueness of a solution. See \textcite{capinski_stochastic_2012} for a proof.

\begin{theorem}\label{thm:sde-solution}
  Provided that both the coefficients $a(t,x)$ and $b(t,x)$ satisfy the following conditions.

  \begin{itemize}
    \item Linear growth in the first variable: there exists $C > 0$ such that

      \begin{align*}
        |a(t,x)| + |b(t,x)| \le C (1 + |x|), \text{ for } t \in [0,T], x \in \mathbb{R}.
      \end{align*}

    \item Lipschitz continuity in the second variable: there exists $K > 0$ such that

      \begin{align*}
        |a(t,x) - a(x,y)| + |b(t,x) - b(t,y)| \le K |x-y|, \text{ for } t \in [0,T], x,y \in \mathbb{R}.
      \end{align*}
  \end{itemize}

  Then \eqref{eq:sde-init-value} has a unique solution with continuous paths such that

  \begin{align*}
    \mathbb{E}\left(\int_0^T X(t)^2 \mathrm{d}t\right) < \infty.
  \end{align*}
\end{theorem}

We now introduce two ways to derive new SDEs from old ones, both with their multidimensional versions. The first, the It\^o formula, allows us to find a SDE satisfied by $F(t,X(t))$ for some function $F(t,x)$ given the SDE satisfied by $X(t)$. The second, the It\^o product rule, gives us a SDE satisfied by the product $X(t)Y(t)$ from SDEs that $X(t)$ and $Y(t)$ satisfy.

\begin{theorem}\label{thm:ito-formula}
  (\textbf{It\^o formula}) If $F : [0,T] \times \mathbb{R} \to \mathbb{R}$ is in $C^{1,2}$ and $X$ is an It\^o process, i.e.

  \begin{align*}
    \mathrm{d}X(t) &= a(t) \mathrm{d}t + b(t) \mathrm{d}W(t)
  \end{align*}

  with $\int_0^T |a(t)| \mathrm{d}t < \infty$ almost surely and $b \in \mathcal{M}^2$.

  Then $F(t,X(t))$ is an It\^o process with stochastic differential

  \begin{align*}
    \mathrm{d}F(t,X(t)) &= \left(F_t(t,X(t)) + F_x(t,X(t)) a(t) + \frac{1}{2} F_{xx}(t,X(t)) b(t)^2 \right) \mathrm{d}t\\
    &\ \ \ \ + F_x(t,X(t)) b(t) \mathrm{d}W(t).
  \end{align*}
\end{theorem}

FIXME: Check that no processes are in $\mathcal{P}^2$ for the simplication on $b(t,x)$ above. This check would also affect the following definitions and theorems.

% FIXME: Solution to dS = u S dt + s S dW

To generalise to higher dimensions, we first need to define multidimensional It\^o processes.

\begin{definition}
  A \textbf{multidimensional It\^o process} is a stochastic process $\mathbf{X}(t) = (X_1(t), X_2(t), \ldots, X_d(t))$ that satisfy

  \begin{align*}
    \mathrm{d}X_i(t) = a_i(t) \mathrm{d}t + \sum_{j=1}^n b_{ij}(t) \mathrm{d}W_j(t), \text{ for } i=1,\ldots,d
  \end{align*}

  where $W_j(t), j=1,\ldots,n$ are $n$ Wiener processes, $a_i(t), i=1,\ldots,d$ are stochastic processes such that $\int_0^T |a_i(t)| \mathrm{d}t < \infty$ and $b_{ij} \in \mathcal{M}^2$ for $i=1,\ldots,d$ and $j=1,\ldots,n$.
\end{definition}

FIXME: Check whether the multidimensional It\^o processes can be defined such that $d=n$ and simplify the following theorems.

FIXME: Uniqueness of characteristics of multi-dimensional It\^o processes (BS, theorem 6.9)

We can now state the multidimensional It\^o formula. A proof can be found in \textcite{capinski_blackscholes_2012}.

\begin{theorem}\label{thm:ito-formula-multi}
  (\textbf{Multidimensional It\^o formula}) If $F : [0,T] \times \mathbb{R}^d \to \mathbb{R}$ of class $C^1$ in the first variable and $C^2$ in the others, and $\mathbf{X}(t)$ is a $d$-dimensional It\^o process driven by $n$ independent Wiener processes. Then $F(t,\mathbf{X}(t)) = F(t,X_1(t),X_2(t),\ldots,X_d(t))$ is an It\^o process with stochastic differential

  \begin{align*}
    \mathrm{d}F(t,\mathbf{X}(t))
    &= F_t(t,\mathbf{X}(t)) \mathrm{d}t + \sum_{i=1}^d F_{x_i}(t,\mathbf{X}(t)) a_i(t) \mathrm{d}t\\
    &\ \ \ \ + \sum_{i=1}^d \left(F_{x_i}(t,\mathbf{X}(t)) \sum_{j=1}^n b_{ij}(t) \mathrm{d}W_j(t) \right)\\
    &\ \ \ \ + \frac{1}{2} \sum_{j=1}^n \sum_{i,l=1}^d F_{x_i x_l}(t,\mathbf{X}(t)) b_{ij}(t)b_{lj}(t) \mathrm{d}t.
  \end{align*}
\end{theorem}

This formula can be used to prove the following lemma which will come handy later on. See \textcite{capinski_blackscholes_2012}.

\begin{lemma}\label{thm:exp-sums-martingale}
  If $\theta_j(t), j=1,\ldots,n$ are deterministic and $W_j(t), j=1,\ldots,d$ are independent Wiener processes, then the stochastic process

  \begin{align*}
    M(t) = \exp \left( \sum_{j=1}^{d} \theta_j(s) \mathrm{d}W_j(s) - \frac{1}{2} \sum_{j=1}^{d} \theta_j(s)^2 \mathrm{d}s \right).
  \end{align*}

  is a martingale.
\end{lemma}

We now turn our attention to product of It\^o processes starting with the unidimensional case. See \textcite{capinski_stochastic_2012} for a proof where it is referred to as integration by parts.

\begin{theorem}
  Given two It\^o processes $X$ and $Y$ satisfying

  \begin{align*}
    \mathrm{d}X(t) &= a_X(t) \mathrm{d}t + b_X(t) \mathrm{d}W(t),\\
    \mathrm{d}Y(t) &= a_Y(t) \mathrm{d}t + b_Y(t) \mathrm{d}W(t),
  \end{align*}

  then the product $XY$ is an It\^o process satisfying

  \begin{align*}
    \mathrm{d}[X(t) Y(t)]
    &= a_X(t) Y(t) \mathrm{d}t + b_X(t) Y(t) \mathrm{d}W(t)\\
    &\ \ \ \ + a_Y(t) X(t) \mathrm{d}t + b_Y(t) X(t) \mathrm{d}W(t)\\
    &\ \ \ \ + b_X(t) b_Y(t) \mathrm{d}t.
  \end{align*}
\end{theorem}

FIXME: Multidimensional It\^o product rule? If not needed, then some paragraph above needs to be changed to remove its mention.

For pricing purposes and since the physical (real) probability $P$ is unknown, we will want to construct a risk-neutral probability $Q$ such that the discounted prices of assets form a martingale under $Q$, i.e. $\mathbb{E}_Q(e^{-rt}S(t) \mid \mathcal{F}_s) = e^{-rs}S(s)$ for $s < t$. The following theorem will allow us to construct such a measure and a Wiener process with respect to it. A proof can be found in \textcite{capinski_blackscholes_2012}.

\begin{theorem}\label{thm:girsanov}
  (\textbf{Girsanov theorem}) Let $\mathbf{W}$ be a $d$-dimensional Wiener process and $\theta_j, j=1,\ldots,d$ be $\mathcal{F}^\mathbf{W}_t$-adapted processes such that

  \begin{align*}
    M(t) = \exp \left( - \sum_{j=1}^d \int_0^t \theta_j(s) \mathrm{d}W_j(s) - \frac{1}{2} \sum_{j=1}^d \int_0^t \theta_j(s)^2 \mathrm{d}s \right)
  \end{align*}

  is a martingale under $P$ and let $Q$ be the measure with density $\frac{\mathrm{d}Q}{\mathrm{d}P} = M(T)$, i.e.

  \begin{align*}
    Q(A) = \int_A M(T) \mathrm{d}P.
  \end{align*}

  Then the process $\mathbf{W}^Q(t) = (W^Q_1(t), W^Q_2(t), \ldots, W^Q_d(t))$ with

  \begin{align*}
    W^Q_j(t) = \int_0^t \theta_j(s) \mathrm{d}s + W_j(t)
  \end{align*}

  is a $d$-dimensional Wiener process under $Q$.
\end{theorem}

In order to construct replicating strategies in the multi-asset Black-Scholes model, we will need one more theorem that allows us to represent a martingale in terms of a stochastic integral. See \textcite{shreve_stochastic_2004}.

\begin{theorem}
  (\textbf{Martingale representation theorem}) Let $\mathbf{W}(t)$ be a $d$-dimensional Wiener process and $M(t)$ be a martingale. Then there is an adapted $d$-dimensional process $\mathbf{\Gamma}(t)$ such that

  \begin{align*}
    M(t) = M(0) + \sum_{j=1}^{d} \int_0^t \Gamma_j(s) \mathrm{d}W_j(s).
  \end{align*}
\end{theorem}

\begin{lemma}\label{lem:ito-integral-girsanov}
  Consider two probability measures $P, Q$ on the same probability space. Let $W$ be a Wiener process under $P$, $W^Q$ a Wiener process under $Q$ and $X$ an It\^o process such that

  \begin{align*}
    \mathrm{d}X(t) &= a(t) \mathrm{d}t + b(t) \mathrm{d}W(t),\\
    \mathrm{d}W^Q(t) &= \theta(t) \mathrm{d}t + \mathrm{d}W(t).\\
  \end{align*}

  Then

  \begin{align*}
    \int_0^t X(s) \mathrm{d}W^Q(s) = \int_0^t a(s) \theta(s) \mathrm{d}s + \int_0^t b(s) \mathrm{d}W(s).
  \end{align*}

  \begin{proof}
    FIXME: Find reference to proof somewhere out there? or write a proof properly + address [0,t] v [0,T].

    If $(X_n)$ is a sequence of simple functions that converges in $L^2$ to $X$, then

    \begin{align*}
      \int_0^T X_n(s) \theta(s) \mathrm{d}s + \int_0^T X_n(s) \mathrm{d}W(s)
      &= \sum_{i=0}^N \left( \int_{t_i}^{t_{i+1}} \xi_{n,i} \theta(s) \mathrm{d}s + \xi_{n,i} (W(t_{i+1}) - W(t_i)) \right)\\
      &= \sum_{i=0}^N \xi_{n,i} \left( \int_{t_i}^{t_{i+1}} \theta(s) \mathrm{d}s + \int_{t_i}^{t_{i+1}} \mathrm{d}W(s) \right)\\
      &= \sum_{i=0}^N \xi_{n,i} (W^Q(t_{i+1}) - W^Q(t_i))\\
      &= \int_0^T X_n(s) \mathrm{d}W^Q(s)\\
      &\underset{L^2}{\longrightarrow} \int_0^T X(s) \mathrm{d}W^Q(s)
    \end{align*}
  \end{proof}
\end{lemma}

\pagebreak
\section{Multi-asset Black-Scholes model}

% Introduce the multidimensional Black-Scholes model. Use [1] as a reference.

The unidimensional Black-Scholes consist of one risk-free asset with price $A(t)$ and one risky asset with price $S(t)$ at time $t$ satisfying the following stochastic differential equations.

\begin{align*}
  \mathrm{d}A(t) &= r A(t) \mathrm{d}t,\\
  \mathrm{d}S(t) &= \mu S(t) \mathrm{d}t + \sigma S(t) \mathrm{d}W(t),
\end{align*}

where $r$ is the risk-free rate, $W$ is a Wiener process with respect to the physical probability, $\mu$ is the drift and $\sigma$ the volatility.

In this section, we expand this model in two ways to arrive at the multi-asset Black-Scholes model with variable coefficients. First, we extend to $d$ risky assets $S_j(t), j =  1, \ldots, d$, each driven by $d$ independent Wiener process $W_i(t), i = 1, \ldots, d$. Second, the coefficients are now functions of time. The dynamics of risky assets becomes

\begin{align}
  \mathrm{d}A(t) &= r(t) A(t) \mathrm{d}t\notag\\
  \mathrm{d}S_i(t) &= \mu_i(t) S_i(t) \mathrm{d}t + \sum_{j=1}^{d} c_{ij}(t) S_i(t) \mathrm{d}W_j(t), \text{ for } i = 1,\ldots,d.\label{eq:multi-bs-eq}
\end{align}

Some further assumptions are required on the coefficients: $\mu_i(t), c_{ij}(t)$ are adapted to the filtration generated by the Wiener processes, have continuous paths and are bounded by a deterministic constant. We'll also assume that the matrix of volatily coefficients $\mathbf{C}(t) = [c_{ij}(t)]_{i,j=1,\ldots,d}$ is invertible.

FIXME: Justificiation of $d$ Wiener processes for $d$ assets?

FIXME: Comment about the fact that assumptions are justified in the following development + references to where.

FIXME: Are they?

FIXME: Recap of what will be done

\subsection{Solution}

The solution to \eqref{eq:multi-bs-eq} is

\begin{align*}
  S_i(t) &= S_i(0) \exp \left( \int_0^t \mu_i(s) \mathrm{d}s - \frac{1}{2} \sum_{j=1}^{d} \int_0^t c_{ij}^2(s) \mathrm{d}s + \sum_{j=1}^d \int_0^t c_{ij}(s) \mathrm{d}W_j(s) \right).
\end{align*}

This can be verified using the multidimensional It\^o formula. Uniqueness follows from \eqref{eq:ito-uniqueness-md} since we assume

FIXME: \^{} Prove it or at least verify it for $d=2$?

\pagebreak
\subsection{Risk-neutral probability}

FIXME: It also has to be equivalent to $P$ which it is since Girsanov implies $Q \ll P$ implies $P \sim Q$.

We want to find a probability measure under which the discounted stock prices form martingales. This will in turn allow us to express derivative prices in terms of conditional expectations.

Very briefly, this is achieved in the unidimensional Black-Scholes model with constant coefficients by noticing that its solution satisfies

\begin{align*}
  S(t)
  &= S(0) \exp \left( \mu t - \frac{1}{2} \sigma^2 t + \sigma W(t) \right)\\
  &= S(0) \exp \left( r t - \frac{1}{2} \sigma^2 t + \sigma \left( \frac{\mu - r}{\sigma} t + W(t) \right) \right)\\
  &= S(0) \exp \left( r t - \frac{1}{2} \sigma^2 t + \sigma W^Q(t) \right)
\end{align*}

where $W^Q(t) = \int_0^t \frac{\mu-r}{\sigma} \mathrm{d}s + W(t)$ is a Wiener process under the probability $Q$ given by the Girsanov theorem \eqref{thm:girsanov} with $d=1$, $a_1(t) = \frac{\mu - r}{\sigma}$. Under this probability, the discounted stock prices then form a martingale so $Q$ is the risk-neutral probability.

We will use a similar technique to obtain a risk-neutral probability for the multi-asset Black-Scholes model with variable coefficients.

First, notice that, for all $i=1,\ldots,d$, if we can find $\theta_j(t), j=1,\ldots,d$ such that

\begin{align}\label{eq:bs-theta}
  \mu_i(t) - r(t) = \sum_{j=1}^d c_{ij}(t) \theta_j(t)
\end{align}

then

\begin{align*}
  S_i(t)
  &= S_i(0) \exp \left( \int_0^t \mu_i(s) \mathrm{d}s - \frac{1}{2} \sum_{j=1}^{d} \int_0^t c_{ij}^2(s) \mathrm{d}s + \sum_{j=1}^d \int_0^t c_{ij}(s) \mathrm{d}W_j(s) \right)\\
  &= S_i(0) \exp \left( \int_0^t r(s) \mathrm{d}s - \frac{1}{2} \sum_{j=1}^{d} \int_0^t c_{ij}^2(s) \mathrm{d}s  + \int_0^t (\mu_i(s) - r(s)) \mathrm{d}s + \sum_{j=1}^d \int_0^t c_{ij}(s) \mathrm{d}W_j(s) \right)\\
  &= S_i(0) \exp \left( \int_0^t r(s) \mathrm{d}s - \frac{1}{2} \sum_{j=1}^{d} \int_0^t c_{ij}^2(s) \mathrm{d}s  + \int_0^t \left(\sum_{j=1}^d c_{ij}(s) \theta_j(s)\right) \mathrm{d}s + \sum_{j=1}^d \int_0^t c_{ij}(s) \mathrm{d}W_j(s) \right)\\
  &= S_i(0) \exp \left( \int_0^t r(s) \mathrm{d}s - \frac{1}{2} \sum_{j=1}^{d} \int_0^t c_{ij}^2(s) \mathrm{d}s  + \sum_{j=1}^d \left( \int_0^t c_{ij}(s) \theta_j(s) \mathrm{d}s + \int_0^t c_{ij}(s) \mathrm{d}W_j(s) \right)\right).
\end{align*}

Furthermore, if

\begin{align*}
  M(t) = \exp \left( - \sum_{j=1}^d \int_0^t \theta_j(s) \mathrm{d}W_j(s) - \frac{1}{2} \sum_{j=1}^d \int_0^t \theta_j(s)^2 \mathrm{d}s \right)
\end{align*}

is a martingale under $P$, then by the Girsanov theorem \eqref{thm:girsanov}, the processes

\begin{align*}
  W^Q_j(t) = \int_0^t \theta_j(s) \mathrm{d}s + W_j(t)
\end{align*}

are Wiener processes under the measure $Q$ with density $\frac{\mathrm{d}Q}{\mathrm{d}P} = M(T)$.

But then, by lemma \eqref{lem:ito-integral-girsanov},

\begin{align*}
  S_i(t)
  &= S_i(0) \exp \left( \int_0^t r(s) \mathrm{d}s - \frac{1}{2} \sum_{j=1}^{d} \int_0^t c_{ij}^2(s) \mathrm{d}s  + \sum_{j=1}^d \left( \int_0^t c_{ij}(s) \theta_j(s) \mathrm{d}s + \int_0^t c_{ij}(s) \mathrm{d}W_j(s) \right)\right)\\
  &= S_i(0) \exp \left( \int_0^t r(s) \mathrm{d}s - \frac{1}{2} \sum_{j=1}^{d} \int_0^t c_{ij}^2(s) \mathrm{d}s  + \sum_{j=1}^d \int_0^t c_{ij}(s) \mathrm{d}W^Q_j(s) \right).
\end{align*}

Therefore, the discounted asset prices are martingales under $Q$ by lemma \eqref{thm:exp-sums-martingale} and since

\begin{align*}
  \tilde{S}_i(t)
  &= e^{-\int_0^t r(s) \mathrm{d}s} S_i(t)
  = S_i(0) \exp \left( - \frac{1}{2} \sum_{j=1}^{d} \int_0^t c_{ij}^2(s) \mathrm{d}s  + \sum_{j=1}^d \int_0^t c_{ij}(s) \mathrm{d}W^Q_j(s) \right).
\end{align*}

In order words, $Q$ is a risk-neutral probability. In summary,

\begin{theorem}
  Let $\theta_j(t), j=1,\ldots,d$ such that

  \begin{itemize}
    \item $\mu_i(t) - r(t) = \sum_{j=1}^d c_{ij}(t) \theta_j(t)$ and
    \item $M(t) = \exp \left( - \sum_{j=1}^d \int_0^t \theta_j(s) \mathrm{d}W_j(s) - \frac{1}{2} \sum_{j=1}^d \int_0^t \theta_j(s)^2 \mathrm{d}s \right)$ is a martingale under the physical probability $P$.
  \end{itemize}

  Then the measure $Q$ with density $\frac{\mathrm{d}Q}{\mathrm{d}P} = M(T)$ is a risk-neutral probability, i.e. the processes $\tilde{S}_i, i=1,\ldots,d$ are martingales under $Q$.
\end{theorem}

Moreover, we can prove that the model assumption that $\mathbf{C}(t)$ is invertible implies the existence of $\theta_j(t), j=1,\ldots,d$ satisfying \eqref{eq:bs-theta}.

\begin{proposition}
  If $\mathbf{C}(t)$ is invertible for all $t$, then there exists a unique process $\mathbf{\theta}(t) = (\theta_1(t), \ldots, \theta_d(t))$ such that

  \begin{align*}
    \mu_i(t) - r(t) = \sum_{j=1}^d c_{ij}(t) \theta_j(t)
  \end{align*}

  for all $j=1,\ldots,d$.

  \begin{proof}
    Indeed, notice that the equation can be rewritten in vector form as

    \begin{align*}
      \mathbf{C}(t) \mathbf{\theta}(t) = \mathbf{\mu}(t) - r(t).
    \end{align*}

    It follows at once that

    \begin{align*}
      \mathbf{\theta}(t) = \mathbf{C}^{-1}(t) (\mathbf{\mu}(t) - r(t)).
    \end{align*}
  \end{proof}
\end{proposition}

FIXME: Corollary with C(t) invertible and the drift and volatility coefficients deterministic. Use previous theorem with lemma from preliminaries.

\subsection{Strategies}

FIXME: Definition of contigent claim

FIXME: Definition of strategy

FIXME: Self-financing condition

FIXME: Definition of martingale strategy

FIXME: Definition of admissible strategy

FIXME: Explanation as to why we need admissiblity?

FIXME: Definition of replicating strategy

FIXME: Representation of contigent claims as processes assumed to be It\^o

\subsection{Completeness}

FIXME: Completeness of the model. (Is it though?)

\subsection{Pricing of derivatives}

FIXME: Pricing with risk-neutral expectations + comment about unknown joint distribution

FIXME: Black-Scholes PDE

\pagebreak
\section{The Fokker-Planck equation}

% Introduce the Fokker-Planck equation. Use [4] as a reference.

FIXME: Intro citing \textcite{pavliotis_stochastic_2014}

FIXME: We work in $(\Omega, \mathcal{F}, \mathcal{F}_t, P)$.

\begin{definition}
  A \textbf{Markov process} is a stochastic process $X(t)$ that satisfies

  \begin{align*}
    \mathbb{E}(f(X(t)) \mid \mathcal{F}^X_{s})
    = \mathbb{E}(f(X(t)) \mid \mathcal{F}_{X(s)})
  \end{align*}

  for $0 \le s < t \le T$ and for all Borel bounded functions $f$.
\end{definition}

These processes are relevant to our discussion since It\^o processes -- and in particular Wiener processes -- are in fact Markov processes.

FIXME: It\^o processes are Markov processes

Informally, the future evolution of a Markov process only depends on its current state, independently from its past evolution. This justifies paying attention to its \textit{transition function}.

\begin{definition}
  Let $\mathbf{X}(t)$ be a $d$-dimensional Markov process. Its \textbf{transition function} is the function $\mu(\Gamma, t; \mathbf{x}, s)$ for $0 \le s < t \le T$, $\mathbf{x} \in \mathbb{R}^d$ and $\Gamma \in \mathcal{B}(\mathbb{R}^d)$ given by

  \begin{align*}
    \mu(\Gamma, t; \mathbf{x}, s) = P(\mathbf{X}(t) \in \Gamma \mid X(s) = \mathbf{x})
  \end{align*}

  where $\mathcal{B}(\mathbb{R}^d)$ denotes the Borel subsets of $\mathbb{R}^d$.
\end{definition}

For fixed $s,t,\mathbf{x}$, the function $\Gamma \mapsto \mu(\Gamma,t;\mathbf{x},s)$ is a probability measure on the $\sigma$-field $\mathcal{B}(\mathbb{R}^d)$ since it is defined as a conditional probability.

FIXME: Definition of time-homogeneity?

In the following, we will consider Markov processes whose transition function admit a density, leading to the next definition.

\begin{definition}
  Let $\mathbf{X}(t)$ be a Markov process with transition function $\mu(\Gamma,t;\mathbf{x},s)$ that admits a density $\rho$ with respect to the Lebesgue measure, i.e.

  \begin{align*}
    \mu(\Gamma,t;\mathbf{x},s) = \int_\Gamma \rho(\mathbf{y},t;\mathbf{x},s) \mathrm{d}\mathbf{y}
  \end{align*}

  for all $\Gamma \in \mathcal{B}(\mathbb{R}^d)$ and $0 \le s < t \le T$.

  We say that $\rho$ is the \textbf{transition probability density} of the Markov process.
\end{definition}

In order to prove the main result of this section, we will make use of the following property of the transition probability density. There exist several versions of this equation including one in terms of the transition function not requiring the existence of a density. However, we only state a single version here for brevity.

\begin{theorem}\label{thm:chapman-kolmogorov}
  Let $\mathbf{X}(t)$ be a Markov process with transition probability density $\rho$. Then

  \begin{align*}
    \rho(\mathbf{y}, t; \mathbf{x}, s) = \int_{\mathbb{R}^d} \rho(\mathbf{y}, t; \mathbf{z}, u) \rho(\mathbf{z}, u; \mathbf{x}, s) \mathrm{d}\mathbf{z}
  \end{align*}

  \begin{proof}
    FIXME
  \end{proof}
\end{theorem}

FIXME: Fokker-Planck

\section{Dupire's equation}

% Give a detailed derivation of the Dupire’s equation (equation starting with ∂C = on page 171 in [2]). ∂T
% Use section 2 from [2] and the section ‘The continuous time theory’ from [3] as a source for the proof.

FIXME

\section{Generalisation to multiple assets}

% Provide the setup and give a detailed proof of Theorem 1 from [2]. This should be based on section 3 from [2]

FIXME

\section{Alternative proof}

% Present the alternative proof of Theorem 1, anded on Appendix A from [2].

FIXME

\section{Numerical example}

% Give a numerical example of how Theorem 1 can be applied to recover aij. You can restrict to the simplest setting of a two dimensional Black-Scholes model.

FIXME

\pagebreak
\printbibliography

\end{document}
